\documentclass{article}
\begin{document}
\section{COMUNICACI\'ON ENTRE PROCESOS}
Los procesos con frecuencia necesitan comunicarse con otros 
procesos. Por tanto es deseable tener mecanismos para esa 
comunicaci\'on en una forma bien estructurada y que no 
utilice interrupciones. En la literatura puede encontrarse el 
t\'ermino {\bf comunicaci\'on entre procesos} o {\bf IPC} 
para referirse a estos mecanismos\footnote{V\'ease por ejemplo
\cite{Tanenbaum}}.

En la llamada IPC, en general se tienen tres problemas, el 
primero es c\'omo un proceso le pasa informaci\'on a otro. El 
segundo problema tiene que ver con asegurarse de que dos o 
m\'as procesos no se estorben mutuamente al efectuar 
actividades cr\'iticas. El tercero se relaciona con la 
secuencia correcta cuando existen dependencias: Si el proceso 
A produce datos y el proceso B los imprime, B tiene que esperar 
hasta que A haya producido algunos datos antes de comenzar a 
imprimir.
\subsection*{Programaci\'on Concurrente}
Es el nombre dado a la notaci\'on y t\'ecnicas de programaci\'on 
utilizados para expresar paralelismo potencial y resolver los 
problemas de sincronizaci\'on y comunicaci\'on resultantes. 
V\'ease \cite{Burns}.
\subsubsection*{Variables compartidas}
Las variables compartidas son objetos a los que m\'as de un 
proceso tienen acceso; la comunicaci\'on por lo tanto, puede 
proceder con cada proceso referenciando esas variables cuando 
sea apropiado.
\subsubsection*{Paso de mensajes}
El paso de mensajes involucra intercambio de datos expl\'icito 
entre dos procesos por medio de un mensaje por medio de un mensaje 
que pasa de un proceso a otro.

La elecci\'on entre variables compartidas y paso de mensajes 
recae en los dise\~nadores del lenguaje o del sistema operativo.

Las variables compartidas son faciles de f\'aciles de soportar 
si hay memoria compartida entre los procesos. Si no es as\'i, 
aun se pueden usar si el hardware incorpora un medio de 
comunicaci\'on.

Similarmente, una primitiva de paso de mensajes puede ser soportada 
a trav\'es de memoria compartida o una red de paso de mensajes 
f\'isica.

\subsection{Condiciones de Competencia}
En un programa concurrente, dos procesos que est\'an colaborando 
podr\'ian compartir cierto almacenamiento com\'un en el que ambos 
pueden leer y escribir. El almacenamiento compartido puee estar 
en la memoria principal o puede ser un archivo compartido; la 
ubicaci\'on de la memoria compartida no altera la naturaleza de 
la comunicaci\'on ni los problemas que surgen. 

Aunque las variables compartidas aparecen como una forma directa 
de pasar informaci\'on entre procesos, su uso sin restricci\'on 
no es confiable y es inseguro debido a problemas de actualizaciones 
m\'ultiples.

Considere dos procesos actualizando una variable compartida $X$, 
con la asignaci\'on
$$
X=X+1;
$$
En la mayoria de los hardware esto no ser\'a ejecutado en una 
operaci\'on {\bf indivisible} (at\'omica), sino que ser\'a 
implementada en tres instrucciones distintas:
\begin{description}
\item[1)]Cargar el valor de $X$ en alg\'un registro (o en la cima 
del stack);
\item[2)]Incrementar en uno el valor en el registro; y
\item[3)]Almacenar el valor en el registro de regreso a $X$.
\end{description}
Como las tres operaciones no son indivisibles, dos procesos 
actualizando la variable simultaneamente podr\'ian entrelazar sus 
acciones y producir un resultado incorrecto. Por ejemplo, si $X$ 
era originalmente 5, los dos procesos podr\'ian cargar en sus 
registros e incrementar y entonces almacenar 6.

\subsubsection*{Condiciones de competencia/carrera}
A las situaciones en las que dos o m\'as procesos leen o escriben 
datos compartidos y el resultado final depende de qui\'en se 
ejecuta precisamente cu\'ando, se denominan {\bf condiciones de 
competencia}. Tambi\'en se puede encontrar para estas situciones, 
el t\'ermino {\bf condiciones de carrera}, v\'ease por ejemplo 
\cite{LDD3}.

Depurar programas que tienen condiciones de carrera no es algo 
sencillo. Los resultados de la mayoria de las ejecuciones de 
prueba est\'an bien, pero en alg\'um momento poco frecuente 
ocurrir\'a algo extra\~no e inexplicable.

\subsubsection*{?`Qu\'e ocasiona las condiciones de carrera?}
La dificultas mencionada en el ejemplo de la variable compartida 
$X$ ocurri\'o debido a que un segundo proceso, digamos proceso B 
empez\'o a utilizar una variable compartida $X$ antes de que el 
primer proceso, digamos el proceso A terminara de trabajar con 
ella.

El problema de evitar las condiciones de carrera se puede 
formular como sigue: parte del tiempo, un proceso est\'a ocupado 
realizando c\'alculos internos y otras cosas que no producen 
condiciones de carrera. Sin embargo, algunas veces un  proceso 
tiene que acceder a la memoria compartida o a archivos compartidos, 
o hacer cosas cr\'iticas que pueden producir carreras. Esa parte 
del programa en la que se accede a la memoria compartida se conoce 
como {regi\'on cr\'itica} o {'bf secci\'on cr\'itica}. Si pudieramos 
ordenar las cosas de manera que dos procesos nunca estuvieran en sus 
regiones cr\'iticas al mismo tiempo, podr\'iamos evitar las carreras.

La clave para evitar problemas aqu\'i y en muchas otras situaciones 
en las que se involucran la memoria compartida, los archivos 
compartidos y cualquier otro recurso compartido es buscar alguna 
manera de evitar que m\'as de un proceso lea y escriba los 
datos compartidos al mismo tiempo. Dicho en otras palabras, lo 
que necesitamos es {\bf exclusi\'on mutua}, cierta forma de asegurar 
que si un proceso est\'a utilizando una variable o archivo compartido, 
los dem\'as procesos se excluir\'an de hacer lo mismo.

\subsubsection{Exclusi\'on mutua son con espera activa}
Existen varios enfoques para lograr la exclusi\'on mutua, de manera 
que mientras un proceso est\'e ocupado actualizando la memoria 
compartida en su regi\'on cr\'itica, ning\'un otro proceso pueda 
entrar a su propia regi\'on cr\'itica y ocasionar problemas.

\subsubsection*{Inhabilitaci\'on de interrupciones}
La soluci\'on m\'as sencilla es hacer que cada proceso inhabilite las 
interrupciones justo despu\'es de ingresar en su regi\'on cr\'itica 
y vuelva a habilitarlas justo antes de salir de ella. Con las 
interrupciones inhabilitadas, no pueden ocurrir interrupciones de reloj. 
Despu\'es de todo, la CPU s\'olo se conmuta de un proceso a otro como 
resultado de interrupciones de reloj o de otro tipo, y con las 
interrupciones desactivadas la CPU no se conmutar\'a a ning\'un otro 
proceso. As\'i, una vez que un proceso ha inhabilitado las 
interrupciones, puede examinar y actualizar la memoria compartida sin 
temor a que otro proceso intervenga.

Este enfoque casi nunca resulta atractivo, porque no es prudente 
conferir a los procesos de usuario la facultad de desactivar las 
interrupciones. Supongamos que uno de ellos lo hiciera, y nunca 
habilitara las interrupciones otra vez. Esto podr\'ia terminar con 
el funcionaminto del sistema. Adem\'as si el sistema es multiprocesador, 
con dos o m\'as CPU, la inhabilitaci\'on de las interrupciones 
afectar\'ia solo a la CPU que ejecutara la instrucci\'on de 
inhabilitaci\'on; las dem\'as seguir\'ian con las interrupciones 
habilitadas y podr\'ian acceder a la memoria compartida.

Por otro lado, en muchos casos es necesario que el kernel mismo 
inhabilite las interrupcionesdurante unas cuantas instrucciones 
mientras actualiza variables o listas. Si ocurriera una interrupci\'on 
en un momento en que la lista de procesos listos, por ejemplo, est\'a 
en un estado inconsistente, ocurrir\'ian condiciones de competencia. 
La conslusi\'on es: la inhabilitaci\'on de interrupciones suele ser 
una t\'ecnica util dentro del sistema operativo mismo pero no es 
apropiada como mecanismo de exclusi\'on mutua general para los 
procesos de usuario.

En la b\'usqueda de soluciones al problemas de exclusi\'on mutua se 
han propuesto dos tipos de enfoque: soluciones no usan ayuda del 
hardware y soluciones que si usan ayuda del hardware. Las primeras 
pretenden ser m\'as portables y se conocen como soluciones software, 
mientras que las segundas pretenden ser m\'as simples. Exploraremos 
superf\/icialmente primero el tipo de soluci\'on software y despu\'es 
el tipo de soluci\'on que si usa ayuda del hardware.

\subsubsection*{Variables de candado}
Supongamos que tenemos una sola variable (de candado/lock) compartida 
cuyo valor inicial es 0. Cuando un proceso quiere entrar en su regi\'on 
cr\'itica, lo primero que hace es probar el candado. Si el candado es 0, 
el proceso le asigna 1 y entra en su regi\'on cr\'itica; sie s 1, el 
proceso espera hasta que el candado vuelve a ser 0. As\'i, un 0 significa 
que ning\'un proceso est\'a en su regi\'on cr\'itica.

Desafortunadamente, esta idea contiene exactamente el mismo defecto 
fatal que vimos en el ejemplo de $X=X+1$. Supongamos que un proceso lee 
el candado y ve que es 0. Antes de que este proceso pueda asignar 1 al 
candado, se planifica otro proceso, el cual se ejecuta y asigna 1 al 
candado. Cuando el primer proceso contin\'ua su ejecuci\'on, asignar\'a 
1 al candado, y dos procesos estar\'an en su regi\'on cr\'itica al mismo 
tiempo.

Podr\'ia pensarse que este problema puede superarse leyendo priemro el 
valor del candado, y verific\'andolo otra vez justo antes de guardadr el 
1 en \'el, pero esto nno sirve de nada. La competencia ocurrir\'ia entonces 
si el segundo proceso modif\/ica el candado justo despu\'es de que el primer 
proceso termin\'o su segunda verif\/icaci\'on.

\subsubsection*{Alternancia estricta}
Un algoritmo de alternancia estricta se muestra a continuaci\'on
\begin{verbatim}
while(TRUE){                       while(TRUE){
  while(turn!=0);/* esperar */       while(turn!=1);/* esperar */
  critical_region_0();                 critical_region_1();
  turn=1;                            turn=0;
  noncritical_region_0();              noncritical_region_1();
}                                  }
       (a)                                (b)
\end{verbatim}
La variable interna {\tt turn}, que inicialmente es 0, indica a quien le 
toca entrar en la regi\'on cr\'itica y examinar o actualizar la memoria 
compartida. En un principio, el proceso 0 inspecciona {\tt turn}, ve que es 
0, y entra en su regi\'on cr\'itica. El proceso 1 tambi\'en ve que {\tt turn} 
es 0 y se mantiene en un ciclo corto probando {\tt turn} continuamente para 
detectar el momento en que cambia a 1. Esta prueba continua de una variable 
hasta que adquiere alg\'un valor se denomina {\bf espera activa},\footnote{En 
el ambito de la programaci\'on en lenguaje ensamblador se conoce con el 
nombre de polling.} y normalmente debe evitarse, ya que desperdicia tiempo 
de CPU. La espera activa solo debe usarse cuando exista una expectativa 
razonable de que la espera ser\'a corta. 

Cuando el proceso 0 sale de la regi\'on cr\'itica, asigna 1 a {\tt turn}, 
a f\/in de que el proceso 1 pueda entrar en su regi\'on cr\'itica. 
Supongamos que el proceso 1 termina su regi\'on cr\'itica r\'apidamente, 
de modo que ambos procesos est\'an en sus regiones no cr\'iticas, y 
{\tt turn} vale 0. Ahora el proceso 0 ejecuta su ciclo completo 
r\'apidamente, regresando a su regi\'on no cr\'itica y regresa al principio 
de su ciclo despu\'es de haber asignado 1 a {\tt turn}. Luego el proceso 
0, termina su regi\'on no cr\'itica y regresa al principio de su ciclo. 
Desafortunadamente, no puede entrar en su regi\'on cr\'itica porque 
{\tt turn} es 1 y el proceso 1 est\'a ocupado en su regi\'on no cr\'itica. 
Dicho de otro modo, la alternancia de turnos no es una buena idea cuando 
un proceso cuando un proceso es mucho m\'as lento que el otro. As\'i pues, 
el proceso 0 est\'a siendo bloqueado por un proceso que no est\'a en su 
regi\'on cr\'itica. De hecho, esta soluci\'on requiere que los dos procesos 
se alternen extrictamente en el ingreso a sus regiones cr\'iticas.

\subsubsection*{La instrucci\'on TSL}
Ahora examinaremos una propuesta que requiere un poco de ayuda del hardware. 
Muchas computadoras, sobre todo las dise\~nadas pensando en m\'ultiples 
procesadores, tienen una instrucci\'on {\tt TEST AN SET LOCK} (TST, probar y 
fijar Lock) que funciona como sigue. La instrucci\'on lee el contenido de la 
palabra en memoria, lo coloca en un registro y luego almacena un valor 
distinto de cero en esa direcci\'on de memoria. Se garantiza que las 
operaciones de leer la palabra y guardar el valor en ella son indivisibles; 
ning\'un otro procesador puede acceder a la palabra de memoria en tanto la 
instrucci\'on no haya terminado. La CPU que ejecuta la instrucci\'on TSL
pone un candado al bus de memoria para que ninguna otra CPU pueda acceder 
a la memoria en tanto no termine.

Para usar la instrucci\'on {\tt TSL} creamos una variable compartida {\tt lock} 
a f\/in de cordinar el acceso a la memoria compartida. Cuando {\tt lock} es 
0, cualquier proceso puede asignarle 1 usando la instrucci\'on {\tt TSL} y 
luego leer o escribir la memoria compartida. Cuando el proceso termina, 
asigna otra vez 0 a {\tt lock} usando una instrucci\'on {\tt MOVE} ordinaria.

?`C\'omo podemos usar esta instrucci\'on para evitar que dos procesos 
entren simultaneamente en sus regiones cr\'iticas? La soluci\'on se da a 
continuaci\'on:
\begin{verbatim}
enter_region:
    TSL register,lock     |copiar lock en register y asignarle 1
    CPM register,#0       |?`era lock 0?
    JNE enter_region      |si no era cero, se asigno 1 a lock y se ejecuta ciclo
    ret                   |volver al invocador; se entro en la region critica


leave_region:
    MOVE lock,#0          |guardar un 0 en lock
    ret                   |volver al invocador
\end{verbatim}
{\tt enter$\_$region} es una subrutina de cuatro instrucciones escrita 
en un lenguaje ensamblador ficticio (pero t\'ipico). La primera instrucci\'on 
copia el valor antiguo de lock en el registro y luego asigna 1 a {'tt lock}. 
Luego se compara el valor antiguo con 0. Si es distinto de 0, el candado ya 
estaba establecido, as\'i que el programa simplemente vuelve al principio 
y lo prueba otra vez. Tarde o temprano el valor de {\tt lock} ser\'a 0 
(cuando el proceso que actualmente est\'a en su regi\'on cr\'itica termine 
lo que est\'a haciendo dentro de dicha regi\'on) y la subrutina regresar\'a, 
con el candado establecido. Liberar el candado es sencillo, pues basta con 
almacenar 0 en {\tt lock}. No se requieren instrucciones especiales.

Ya tenemos una soluci\'on al problema de la regi\'on cr\'itica que es 
directa. Antes de entrar en su regi\'on cr\'itica un proceso invoca 
{\tt enter$\_$region}, la cual realiza espera activa hasta que el candado 
est\'a libre; luego adquiere el candado y regresa. Despu\'es de la regi\'on 
cr\'itica el proceso invoca {\tt leave$\_$region}, que almacena un 0 en 
{\tt lock}.

\subsubsection*{Implementaci\'on en xv6}
En el archivo {\tt x86.h} de xv6 encontramos la funci\'on
\begin{verbatim}
static inline uint
xchg(volatile uint *addr, uint newval)
{
  uint result;
  
  // The + in "+m" denotes a read-modify-write operand.
  asm volatile("lock; xchgl %0, %1" :
               "+m" (*addr), "=a" (result) :
               "1" (newval) :
               "cc");
  return result;
}
\end{verbatim}
Tambi\'en en el archivo {\tt spinlock.c} se tiene la implementaci\'on 
de spinlocks (locks de giro o candados de giro) para exclusi\'on mutua.
\begin{verbatim}
// Acquire the lock.
// Loops (spins) until the lock is acquired.
// Holding a lock for a long time may cause
// other CPUs to waste time spinning to acquire it.
void
acquire(struct spinlock *lk)
{
  pushcli(); // disable interrupts to avoid deadlock.
  if(holding(lk))
    panic("acquire");

  // The xchg is atomic.
  // It also serializes, so that reads after acquire are not
  // reordered before it. 
  while(xchg(&lk->locked, 1) != 0)
    ;

  // Record info about lock acquisition for debugging.
  lk->cpu = cpu;
  getcallerpcs(&lk, lk->pcs);
}

// Release the lock.
void
release(struct spinlock *lk)
{
  if(!holding(lk))
    panic("release");

  lk->pcs[0] = 0;
  lk->cpu = 0;

  // The xchg serializes, so that reads before release are 
  // not reordered after it.  The 1996 PentiumPro manual (Volume 3,
  // 7.2) says reads can be carried out speculatively and in
  // any order, which implies we need to serialize here.
  // But the 2007 Intel 64 Architecture Memory Ordering White
  // Paper says that Intel 64 and IA-32 will not move a load
  // after a store. So lock->locked = 0 would work here.
  // The xchg being asm volatile ensures gcc emits it after
  // the above assignments (and after the critical section).
  xchg(&lk->locked, 0);

  popcli();
}
\end{verbatim}
Una nota sobre la instrucci\'on {\tt XCHG} de los microprocesadores 
Intel.\par
\noindent{\tt XCHG}\par
\noindent La instrucci\'on de intercambio ({\tt XCHG}) intercambia 
el contenido de un registrocon el contenido de cualquier otro 
registro o una localidad de memoria. La instrucci\'on {\tt XCHG} 
no se puede ejecutar en registros de segmento ni con datos de 
memoria a memoria. Los intercambios son de tama\~no byte, palabra 
o doble palabra (solo en 80386/80486 o superiores). En la siguiente 
tabla aparecen las formas de la instrucci\'on {\tt XCHG}
\begin{center}
\begin{tabular}{|ll}\hline
{\tt Simb\'olica}&{\tt Funciones}\\\hline
{\tt XCHG reg,reg}&Intercambia registros de byte, palabra y 
doble palabra\\\hline
{\tt XCHG reg,mem}&Intercambia datos en la memoria byte, palabra 
o doble palabra, con datos del registro.
\end{tabular}
\end{center}


\begin{thebibliography}{9}
\bibitem{Burns}Alan Burns, Andy Wellings, ``Real-Time Systems and 
Programming Languages'', Addison-Wesley, 3$^{\mbox{a}}$ Edici\'on, 
Pearson Education Limited 2001.
\bibitem{LDD3}Jonathan Corbet, Alessandro Rubini, Greg Kroah-Hartman, 
``Drivers en Linux, T\'ecnicas y soluciones para el desarrollo de 
Controladores'', O$^{\prime}$Reilly Anaya Multimedia, 2005.
\bibitem{Tanenbaum}Andrew S. Tanenbaum, ``Sistemas Operativos, 
Dise\~no e implementaci\'on,'' Editorial Pearson, 2002.
\end{thebibliography}
\end{document}
